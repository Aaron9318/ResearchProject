{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMY+BJ8NRvju8gf/C5PVYG0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aaron9318/ResearchProject/blob/main/MLP/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xujvjpA0sRU"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import random\n",
        "import seaborn\n",
        "\n",
        "seaborn.set(style='whitegrid'); seaborn.set_context('talk')\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "iris_data = load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TRkhaQ50zY5"
      },
      "source": [
        "\n",
        "import pandas\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "\n",
        "dataset = iris_data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljpGoCks1Yvi"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ7Ar2v51Gr-"
      },
      "source": [
        "random.seed(123)\n",
        "\n",
        "def separate_data():\n",
        "    A = iris_dataset[0:40]\n",
        "    tA = iris_dataset[40:50]\n",
        "    B = iris_dataset[50:90]\n",
        "    tB = iris_dataset[90:100]\n",
        "    C = iris_dataset[100:140]\n",
        "    tC = iris_dataset[140:150]\n",
        "    train = np.concatenate((A,B,C))\n",
        "    test =  np.concatenate((tA,tB,tC))\n",
        "    return train,test\n",
        "\n",
        "train_porcent = 80 # Porcent Training \n",
        "test_porcent = 20 # Porcent Test\n",
        "iris_dataset = np.column_stack((iris_data.data,iris_data.target.T)) #Join X and Y\n",
        "iris_dataset = list(iris_dataset)\n",
        "random.shuffle(iris_dataset)\n",
        "\n",
        "Filetrain, Filetest = separate_data()\n",
        "\n",
        "train_X = np.array([i[:4] for i in Filetrain])\n",
        "train_y = np.array([i[4] for i in Filetrain])\n",
        "test_X = np.array([i[:4] for i in Filetest])\n",
        "test_y = np.array([i[4] for i in Filetest])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKzqFWQe1NLY"
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
        "import random\n",
        "\n",
        "class MultiLayerPerceptron(BaseEstimator, ClassifierMixin): \n",
        "    def __init__(self, params=None):     \n",
        "        if (params == None):\n",
        "            self.inputLayer = 4                        # Input Layer\n",
        "            self.hiddenLayer = 5                       # Hidden Layer\n",
        "            self.outputLayer = 3                       # Outpuy Layer\n",
        "            self.learningRate = 0.005                  # Learning rate\n",
        "            self.max_epochs = 600                      # Epochs\n",
        "            self.iasHiddenValue = -1                   # Bias HiddenLayer\n",
        "            self.BiasOutputValue = -1                  # Bias OutputLayer\n",
        "            self.activation = self.ativacao['sigmoid'] # Activation function\n",
        "            self.deriv = self.derivada['sigmoid']\n",
        "        else:\n",
        "            self.inputLayer = params['InputLayer']\n",
        "            self.hiddenLayer = params['HiddenLayer']\n",
        "            self.OutputLayer = params['OutputLayer']\n",
        "            self.learningRate = params['LearningRate']\n",
        "            self.max_epochs = params['Epocas']\n",
        "            self.BiasHiddenValue = params['BiasHiddenValue']\n",
        "            self.BiasOutputValue = params['BiasOutputValue']\n",
        "            self.activation = self.ativacao[params['ActivationFunction']]\n",
        "            self.deriv = self.derivada[params['ActivationFunction']]\n",
        "        \n",
        "        'Starting Bias and Weights'\n",
        "        self.WEIGHT_hidden = self.starting_weights(self.hiddenLayer, self.inputLayer)\n",
        "        self.WEIGHT_output = self.starting_weights(self.OutputLayer, self.hiddenLayer)\n",
        "        self.BIAS_hidden = np.array([self.BiasHiddenValue for i in range(self.hiddenLayer)])\n",
        "        self.BIAS_output = np.array([self.BiasOutputValue for i in range(self.OutputLayer)])\n",
        "        self.classes_number = 3 \n",
        "        \n",
        "    pass\n",
        "    \n",
        "    def starting_weights(self, x, y):\n",
        "        return [[2  * random.random() - 1 for i in range(x)] for j in range(y)]\n",
        "\n",
        "    ativacao = {\n",
        "         'sigmoid': (lambda x: 1/(1 + np.exp(-x))),\n",
        "            'tanh': (lambda x: np.tanh(x)),\n",
        "            'Relu': (lambda x: x*(x > 0)),\n",
        "               }\n",
        "    derivada = {\n",
        "         'sigmoid': (lambda x: x*(1-x)),\n",
        "            'tanh': (lambda x: 1-x**2),\n",
        "            'Relu': (lambda x: 1 * (x>0))\n",
        "               }\n",
        " \n",
        "    def Backpropagation_Algorithm(self, x):\n",
        "        DELTA_output = []\n",
        "        'Stage 1 - Error: OutputLayer'\n",
        "        ERROR_output = self.output - self.OUTPUT_L2\n",
        "        DELTA_output = ((-1)*(ERROR_output) * self.deriv(self.OUTPUT_L2))\n",
        "        \n",
        "        arrayStore = []\n",
        "        'Stage 2 - Update weights OutputLayer and HiddenLayer'\n",
        "        for i in range(self.hiddenLayer):\n",
        "            for j in range(self.OutputLayer):\n",
        "                self.WEIGHT_output[i][j] -= (self.learningRate * (DELTA_output[j] * self.OUTPUT_L1[i]))\n",
        "                self.BIAS_output[j] -= (self.learningRate * DELTA_output[j])\n",
        "      \n",
        "        'Stage 3 - Error: HiddenLayer'\n",
        "        delta_hidden = np.matmul(self.WEIGHT_output, DELTA_output)* self.deriv(self.OUTPUT_L1)\n",
        " \n",
        "        'Stage 4 - Update weights HiddenLayer and InputLayer(x)'\n",
        "        for i in range(self.OutputLayer):\n",
        "            for j in range(self.hiddenLayer):\n",
        "                self.WEIGHT_hidden[i][  j] -= (self.learningRate * (delta_hidden[j] * x[i]))\n",
        "                self.BIAS_hidden[j] -= (self.learningRate * delta_hidden[j])\n",
        "                \n",
        "    def show_err_graphic(self,v_erro,v_epoca):\n",
        "        plt.figure(figsize=(9,4))\n",
        "        plt.plot(v_epoca, v_erro, \"m-\",color=\"b\", marker=11)\n",
        "        plt.xlabel(\"Number of Epochs\")\n",
        "        plt.ylabel(\"Squared error (MSE) \");\n",
        "        plt.title(\"Error Minimization\")\n",
        "        plt.show()\n",
        "\n",
        "    def predict(self, X, y):\n",
        "        'Returns the predictions for every element of X'\n",
        "        my_predictions = []\n",
        "        'Forward Propagation'\n",
        "        forward = np.matmul(X,self.WEIGHT_hidden) + self.BIAS_hidden\n",
        "        forward = np.matmul(forward, self.WEIGHT_output) + self.BIAS_output\n",
        "                                 \n",
        "        for i in forward:\n",
        "           my_predictions.append(max(enumerate(i), key=lambda x:x[1])[0])\n",
        "            \n",
        "        print(\" Number of Sample  | Class |  Output |  Hoped Output  \")   \n",
        "        for i in range(len(my_predictions)):\n",
        "            if(my_predictions[i] == 0): \n",
        "                print(\"id:{}    | Iris-Setosa  |  Output: {} | H : {} \".format(i, my_predictions[i], y[i]))\n",
        "            elif(my_predictions[i] == 1): \n",
        "                print(\"id:{}    | Iris-Versicolour    |  Output: {} | H : {}  \".format(i, my_predictions[i], y[i]))\n",
        "            elif(my_predictions[i] == 2): \n",
        "                print(\"id:{}    | Iris-Iris-Virginica   |  Output: {} | H : {}  \".format(i, my_predictions[i], y[i]))\n",
        "                \n",
        "        return my_predictions,forward\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y):  \n",
        "        count_epoch = 1\n",
        "        total_error = 0\n",
        "        n = len(X); \n",
        "        epoch_array = []\n",
        "        error_array = []\n",
        "        W0 = []\n",
        "        W1 = []\n",
        "        while(count_epoch <= self.max_epochs):\n",
        "            for idx,inputs in enumerate(X): \n",
        "                self.output = np.zeros(self.classes_number)\n",
        "                'Stage 1 - (Forward Propagation)'\n",
        "                self.OUTPUT_L1 = self.activation((np.dot(inputs, self.WEIGHT_hidden) + self.BIAS_hidden.T))\n",
        "                self.OUTPUT_L2 = self.activation((np.dot(self.OUTPUT_L1, self.WEIGHT_output) + self.BIAS_output.T))\n",
        "                'Stage 2 - One-Hot-Encoding'\n",
        "                if(y[idx] == 0): \n",
        "                    self.output = np.array([1,0,0]) #Class1 {1,0,0}\n",
        "                elif(y[idx] == 1):\n",
        "                    self.output = np.array([0,1,0]) #Class2 {0,1,0}\n",
        "                elif(y[idx] == 2):\n",
        "                    self.output = np.array([0,0,1]) #Class3 {0,0,1}\n",
        "                \n",
        "                square_error = 0\n",
        "                for i in range(self.OutputLayer):\n",
        "                    erro = (self.output[i] - self.OUTPUT_L2[i])**2\n",
        "                    square_error = (square_error + (0.05 * erro))\n",
        "                    total_error = total_error + square_error\n",
        "         \n",
        "                'Backpropagation : Update Weights'\n",
        "                self.Backpropagation_Algorithm(inputs)\n",
        "                \n",
        "            total_error = (total_error / n)\n",
        "            if((count_epoch % 50 == 0)or(count_epoch == 1)):\n",
        "                print(\"Epoch \", count_epoch, \"- Total Error: \",total_error)\n",
        "                error_array.append(total_error)\n",
        "                epoch_array.append(count_epoch)\n",
        "                \n",
        "            W0.append(self.WEIGHT_hidden)\n",
        "            W1.append(self.WEIGHT_output)\n",
        "             \n",
        "                \n",
        "            count_epoch += 1\n",
        "        self.show_err_graphic(error_array,epoch_array)\n",
        "        \n",
        "        plt.plot(W0[0])\n",
        "        plt.title('Weight Hidden update during training')\n",
        "        plt.legend(['neuron1', 'neuron2', 'neuron3', 'neuron4', 'neuron5'])\n",
        "        plt.ylabel('Value Weight')\n",
        "        plt.show()\n",
        "        \n",
        "        plt.plot(W1[0])\n",
        "        plt.title('Weight Output update during training')\n",
        "        plt.legend(['neuron1', 'neuron2', 'neuron3'])\n",
        "        plt.ylabel('Value Weight')\n",
        "        plt.show()\n",
        "\n",
        "        return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtcs_yvL1SN1"
      },
      "source": [
        "def show_test():\n",
        "    ep1 = [0,100,200,300,400,500,600,700,800,900,1000,1500,2000]\n",
        "    h_5 = [0,60,70,70,83.3,93.3,96.7,86.7,86.7,76.7,73.3,66.7,66.7]\n",
        "    h_4 = [0,40,70,63.3,66.7,70,70,70,70,66.7,66.7,43.3,33.3]\n",
        "    h_3 = [0,46.7,76.7,80,76.7,76.7,76.6,73.3,73.3,73.3,73.3,76.7,76.7]\n",
        "    plt.figure(figsize=(10,4))\n",
        "    l1, = plt.plot(ep1, h_3, \"m-\",color='b',label=\"node-3\", marker=11)\n",
        "    l2, = plt.plot(ep1, h_4, \"m-\",color='g',label=\"node-4\", marker=8)\n",
        "    l3, = plt.plot(ep1, h_5, \"m-\",color='r',label=\"node-5\", marker=5)\n",
        "    plt.legend(handles=[l1,l2,l3], loc=1)\n",
        "    plt.xlabel(\"number of Epochs\");plt.ylabel(\"% Hits\");\n",
        "    plt.title(\"Number of Hidden Layers - Performance\")\n",
        "    \n",
        "    ep2 = [0,100,200,300,400,500,600,700]\n",
        "    tanh = [0.18,0.027,0.025,0.022,0.0068,0.0060,0.0057,0.00561]\n",
        "    sigm = [0.185,0.0897,0.060,0.0396,0.0343,0.0314,0.0296,0.0281]\n",
        "    Relu = [0.185,0.05141,0.05130,0.05127,0.05124,0.05123,0.05122,0.05121]\n",
        "    plt.figure(figsize=(10,4))\n",
        "    l1 , = plt.plot(ep2, tanh, \"m-\",color='b',label=\"Hyperbolic Tangent\",marker=11)\n",
        "    l2 , = plt.plot(ep2, sigm, \"m-\",color='g',label=\"Sigmoide\", marker=8)\n",
        "    l3 , = plt.plot(ep2, Relu, \"m-\",color='r',label=\"ReLu\", marker=5)\n",
        "    plt.legend(handles=[l1,l2,l3], loc=1)\n",
        "    plt.xlabel(\"Epoch\");plt.ylabel(\"Error\");plt.title(\"Activation Functions - Performance\")\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "    names = [\"Hyperbolic Tangent\",\"Sigmoide\",\"ReLU\"]\n",
        "    x1 = [2.0,4.0,6.0]\n",
        "    plt.bar(x1[0],53.4,0.4,color='b')\n",
        "    plt.bar(x1[1],96.7,0.4,color='g')\n",
        "    plt.bar(x1[2],33.2,0.4,color='r')\n",
        "    plt.xticks(x1,names)\n",
        "    plt.ylabel('% Hits')\n",
        "    plt.title('Hits - Activation Functions')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8jJGgYx1eE4"
      },
      "source": [
        "show_test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E461JqJ1mCE"
      },
      "source": [
        "dictionary = {'InputLayer':4, 'HiddenLayer':5, 'OutputLayer':3,\n",
        "              'Epocas':700, 'LearningRate':0.005,'BiasHiddenValue':-1, \n",
        "              'BiasOutputValue':-1, 'ActivationFunction':'sigmoid'}\n",
        "\n",
        "Perceptron = MultiLayerPerceptron(dictionary)\n",
        "Perceptron.fit(train_X,train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ix7ejN_foGw"
      },
      "source": [
        "https://www.kaggle.com/vitorgamalemos/multilayer-perceptron-from-scratch#About-this-notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gcTBONRVysX"
      },
      "source": [
        "prev, probas = Perceptron.predict(test_X,test_y)\n",
        "hits = n_set = n_vers = n_virg = 0\n",
        "score_set = score_vers = score_virg = 0\n",
        "for j in range(len(test_y)):\n",
        "    if(test_y[j] == 0): n_set += 1\n",
        "    elif(test_y[j] == 1): n_vers += 1\n",
        "    elif(test_y[j] == 2): n_virg += 1\n",
        "        \n",
        "for i in range(len(test_y)):\n",
        "    if test_y[i] == prev[i]: \n",
        "        hits += 1\n",
        "    if test_y[i] == prev[i] and test_y[i] == 0:\n",
        "        score_set += 1\n",
        "    elif test_y[i] == prev[i] and test_y[i] == 1:\n",
        "        score_vers += 1\n",
        "    elif test_y[i] == prev[i] and test_y[i] == 2:\n",
        "        score_virg += 1    \n",
        "         \n",
        "hits = (hits / len(test_y))*100\n",
        "faults = 100 - hits\n",
        "print(len(test_X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJl7wIgnqoUK"
      },
      "source": [
        "print(prev)\n",
        "print(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwbzuuswYKhH"
      },
      "source": [
        "graph_hits = []\n",
        "print(\"Porcents :\",\"%.2f\"%(hits),\"% hits\",\"and\",\"%.2f\"%(faults),\"% faults\")\n",
        "#print(\"Total samples of test\",n_samples)\n",
        "print(\"*Iris-Setosa:\",n_set,\"samples\")\n",
        "print(\"*Iris-Versicolour:\",n_vers,\"samples\")\n",
        "print(\"*Iris-Virginica:\",n_virg,\"samples\")\n",
        "\n",
        "graph_hits.append(hits)\n",
        "graph_hits.append(faults)\n",
        "labels = 'Hits', 'Faults';\n",
        "sizes = [96.5, 3.3]\n",
        "explode = (0, 0.14)\n",
        "\n",
        "fig1, ax1 = plt.subplots();\n",
        "ax1.pie(graph_hits, explode=explode,colors=['blue','red'],labels=labels, autopct='%1.1f%%',\n",
        "shadow=True, startangle=90)\n",
        "ax1.axis('equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}